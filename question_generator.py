"""
AI-ONLY Question Generation Engine for Toto Fryn.
All questions are generated by Ollama LLM with sophisticated curriculum-aligned prompts.
No local templates - 100% AI-generated questions with genuine educational value.
"""

import time
import json
import re
import random
from typing import Dict, List, Tuple
from ollama_client import query_model


class QuestionGenerator:
    """
    Generates 100% AI-created curriculum-aligned questions using Ollama.
    All questions are created by the AI model with sophisticated prompts that include:
    - Curriculum competences and learning outcomes
    - Uganda-specific contexts and examples
    - Appropriate difficulty levels (1-5)
    - High-quality educational content
    
    No local question templates are used - pure AI generation only.
    """

    # Cache for generated questions by (level, subject, theme, difficulty)
    _ollama_question_cache: Dict[Tuple[str, str, str, int], List[Dict]] = {}

    def __init__(self, level: str, subject: str, theme: str, difficulty: int = 2,
                 validator=None, ollama_questioner: str = None):
        """Initialize question generator."""
        self.level = level.upper()
        self.subject = subject.lower()
        self.theme = theme
        self.difficulty = max(1, min(difficulty, 5))  # Clamp 1-5
        self.validator = validator
        self.ollama_questioner = ollama_questioner or "llama3.2:1b"

    def generate_question(self) -> Dict:
        """
        Generate a single AI-created question using Ollama.
        Returns a curriculum-aligned question with genuine educational content.
        """
        
        # Check cache first for efficiency
        cache_key = (self.level, self.subject, self.theme, self.difficulty)
        cached_questions = QuestionGenerator._ollama_question_cache.get(cache_key)
        if cached_questions and len(cached_questions) > 0:
            q = cached_questions.pop(0)
            print(f"[Using cached Ollama question for {self.theme}]")
            return q

        print(f"[Generating AI question: {self.level} {self.subject} - {self.theme} (Difficulty {self.difficulty}/5)]")
        
        try:
            # Build sophisticated prompt with curriculum context
            prompt = self._build_curriculum_prompt()
            
            # Call Ollama with the prompt
            response = query_model(prompt, model=self.ollama_questioner)
            
            # Parse the AI-generated questions from response
            questions = self._parse_ai_response(response)
            
            if questions and len(questions) > 0:
                # Cache remaining questions (if more than one was generated)
                if len(questions) > 1:
                    QuestionGenerator._ollama_question_cache[cache_key] = questions[1:]
                
                return questions[0]
            else:
                raise ValueError("Could not extract valid questions from AI response")
                
        except Exception as e:
            # No fallback - report the error clearly
            print(f"[ERROR] Failed to generate AI question: {e}")
            raise

    def _build_curriculum_prompt(self) -> str:
        """
        Build a sophisticated prompt that guides Ollama to generate genuine,
        high-quality educational questions aligned with curriculum and Uganda context.
        """
        
        # Get curriculum competences and learning outcomes for this theme
        competences = []
        if self.validator:
            try:
                competences = self.validator.get_all_competences(self.level, self.subject)[:8]
            except Exception:
                pass

        # Difficulty level guidance
        difficulty_descriptions = {
            1: "very easy - appropriate for beginners, straightforward thinking, simple vocabulary",
            2: "easy - requires basic understanding, one or two steps, age-appropriate",
            3: "medium - requires reasoning and multi-step thinking, moderate vocabulary",
            4: "hard - requires critical thinking and problem-solving skills",
            5: "very hard - requires deep understanding, analysis, and complex reasoning"
        }

        # Subject-specific guidance for quality prompts
        subject_guidance = {
            "mathematics": (
                "Create a problem-solving question that could be arithmetic, geometry, measurement, "
                "data interpretation, or logical reasoning. Make it practical and use real Uganda contexts. "
                "Include specific numbers appropriate for the difficulty and level. "
                "Ensure it teaches a mathematical concept, not just computation."
            ),
            "english": (
                "Create a language learning question testing vocabulary, grammar, reading comprehension, "
                "spelling, sentence construction, or writing skills. Use age-appropriate language and "
                "Uganda-relevant contexts. Make it engaging and educational. "
                "For P1, use simple words and concepts. For P3, use more complex language."
            ),
            "science": (
                "Create a science question about living things, the environment, health, matter, energy, or "
                "physical phenomena. Use Uganda examples: local animals (antelopes, hyenas, pangolins), "
                "plants (mangoes, cassava, coffee), weather patterns, water sources, or farming. "
                "Make observations practical and age-appropriate."
            )
        }

        base_guidance = subject_guidance.get(self.subject, 
            "Create an educational question for a primary school student.")

        prompt = f"""You are an expert educational AI tutor creating curriculum-aligned questions for primary school children in Uganda.

TASK: Generate EXACTLY ONE high-quality educational question.

CONTEXT:
- Level: {self.level} (Primary {self.level[1:] if len(self.level) > 1 else self.level})
- Subject: {self.subject.title()}
- Theme: {self.theme}
- Difficulty Level: {self.difficulty}/5 - {difficulty_descriptions.get(self.difficulty, "medium")}

CURRICULUM ALIGNMENT:
These are the learning competences for {self.level} {self.subject}:
{chr(10).join(f"  • {c}" for c in competences) if competences else "  • General competences in " + self.subject}

QUESTION REQUIREMENTS:
1. {base_guidance}

2. UGANDA CONTEXT - Make the question relevant to Ugandan students:
   - Use Ugandan currency (Ugandan Shillings, not dollars/pounds)
   - Include local examples: animals (antelopes, hyenas, pangolins, monkeys), fruits (mangoes, 
     matooke, guavas, pawpaws, passion fruit), vegetables (cassava, sweet potato, beans), crops (coffee, tea),
     places (villages, towns, rivers), activities (farming, markets, school life)
   - Reference Ugandan culture and daily life
   - Use names like: Akello, Nalongo, Kamugisha, Zainab, Musa, Hasana

3. QUALITY STANDARDS:
   - Question must be clear and unambiguous
   - Appropriate vocabulary for {self.level}
   - Should teach a concept, not just test rote memorization
   - Expected answer must be clear and correct
   - Hint should guide thinking WITHOUT revealing the answer
   - Avoid trick questions

4. DIFFICULTY INTERPRETATION (for {self.difficulty}/5):
   {difficulty_descriptions.get(self.difficulty, "medium - requires some thinking")}

RESPONSE FORMAT (MUST be ONLY the JSON object, no markdown or extra text):
{{
  "question_text": "Clear, age-appropriate question aligned with {self.theme}",
  "expected_answer": "The correct answer or acceptable answer patterns",
  "type": "short_answer",
  "difficulty": {self.difficulty},
  "hint": "A helpful hint that guides thinking without revealing the answer",
  "context": "{self.theme}"
}}

CRITICAL RULES:
- Return ONLY valid JSON, nothing else
- question_text must be clear and appropriate for {self.level}
- expected_answer must be concise and correct
- hint must guide without spoiling
- Include Uganda context naturally in the question
- Make the question genuine and educational
- difficulty must match the complexity

Now generate the question:"""

        return prompt

    def _parse_ai_response(self, response: str) -> List[Dict]:
        """Parse AI-generated questions from Ollama response."""
        
        questions = []
        
        try:
            # Extract JSON object from response
            # Look for { ... } pattern in the response
            json_match = re.search(r'\{[\s\S]*\}', response.strip())
            
            if not json_match:
                raise ValueError("No JSON object found in response")
            
            json_text = json_match.group(0)
            question_data = json.loads(json_text)
            
            # Validate and normalize question structure
            question = {
                "question_id": f"{self.level}_{self.subject}_{self.theme}_{int(time.time() * 1000) % 100000}",
                "question_text": str(question_data.get("question_text", "")).strip(),
                "expected_answer": str(question_data.get("expected_answer", "")).strip(),
                "type": str(question_data.get("type", "short_answer")).strip().lower(),
                "difficulty": int(question_data.get("difficulty", self.difficulty)),
                "hint": str(question_data.get("hint", "Think carefully about the question.")).strip(),
                "context": str(question_data.get("context", self.theme)).strip(),
                "level": self.level,
                "subject": self.subject,
                "theme": self.theme
            }
            
            # Validate required fields
            if not question["question_text"]:
                raise ValueError("Missing question_text in parsed response")
            if not question["expected_answer"]:
                raise ValueError("Missing expected_answer in parsed response")
            
            # Clamp difficulty to valid range
            question["difficulty"] = max(1, min(question["difficulty"], 5))
            
            questions.append(question)
            
        except json.JSONDecodeError as e:
            raise ValueError(f"Failed to parse JSON from AI response: {e}\nResponse preview: {response[:300]}")
        except ValueError as e:
            raise ValueError(f"Invalid question structure from AI: {e}")
        except Exception as e:
            raise ValueError(f"Error processing AI response: {e}")
        
        return questions

    def adjust_difficulty_for_question(self, new_difficulty: int) -> None:
        """Adjust difficulty level for subsequent questions."""
        if 1 <= new_difficulty <= 5:
            self.difficulty = new_difficulty
        else:
            raise ValueError(f"Difficulty must be between 1 and 5, got {new_difficulty}")

    def clear_cache(self) -> None:
        """Clear the question cache."""
        QuestionGenerator._ollama_question_cache.clear()

    def generate_multiple_questions(self, count: int = 5) -> List[Dict]:
        """Generate multiple questions for a lesson."""
        return [self.generate_question() for _ in range(count)]
